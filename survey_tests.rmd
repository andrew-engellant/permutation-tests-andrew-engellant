---
html_document:
  toc: yes
  toc_depth: 6
  number_sections: yes
  toc_float: yes
  code_folding: hide
  theme: flatly
  code_download: yes
author: "Andrew Engellant"
date: "`r format(Sys.time(), '%d %B, %Y')`"
title: "Permutation Tests"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```


## Introduction

This R-Markdown holds an assignment extending our Week 1 discussion
of permutation tests. That lecture contains most of the background
material for the assignment, but let me know if you have further questions.

We'll begin by recapitulating the material from the lecture. Then
I'll ask you to extend that work. 

```{r data-input, message=F}

d <- read_tsv("satisfaction_survey.txt")

```


### Difference in Means by Sex

The satisfaction scores by assigned sex^[
You might wonder at this use of "assigned sex" rather than the 
more-common-in-a-business-context "gender" for this column name. 
It's not a point that needs belaboring here, but
"assigned sex" is a more accurate term for a male/female column than "gender". If
you'd like to learn more about this I'd be happy to chat about it. ] 
show lower satisfaction for non-male employees: 

```{r mean-sat, echo=F, message=F}
d %>% 
  group_by(assigned_sex) %>% 
  summarize(`Mean Satisfaction` = mean(satisfaction),
            `SD Satisfaction` = sd(satisfaction),
            N = n()) %>% 
  rename(Gender = assigned_sex) %>% 
  arrange(`Mean Satisfaction`) %>% 
  knitr::kable(digits=2)

```

The original question from HR was whether or not the difference between males and 
females is due to chance. 

Since the survey represents a census, we shouldn't do something simple, like a t-test,
that's designed to test for the difference between means. Instead we can test whether or 
not the association between the "labels" of assigned sex and the "scores" of satisfaction are 
is likely if the two columns are independent. 

We can explore this question with a permutation test. The next code block performs the 
test and visualizes the results.

```{r mean-permute, cache=T}
# Using "cache=T" means that the simulation is only run once and then stored. 
# This is convenient for long-running calculations, but you should turn it off
# if you make changes to the code and need the block to be re-run.

get.assigned.sex.diff <- function(x){
  male.score <- mean(x$satisfaction[x$assigned_sex=="male"])
  female.score <- mean(x$satisfaction[x$assigned_sex=="female"])
  return(male.score - female.score)
}

actual.value <- get.assigned.sex.diff(d) 

n.sim <- 9999

results <- tibble(statistic = c(actual.value,
                                rep(NA,n.sim)))
new.d <- d %>% 
  select(assigned_sex,satisfaction)

for(i in 2:nrow(results)){
  new.d$assigned_sex <- sample(new.d$assigned_sex)
  results$statistic[i] <- get.assigned.sex.diff(new.d)
}

ggplot(results,
       aes(x=statistic)) + 
  geom_density() + 
  geom_vline(xintercept=actual.value,color="red") + 
  theme_minimal() + 
  labs(x="Male Mean Minus Female Mean",
       y="")

```

As we can see from the histogram, the value we we saw, `r round(actual.value,3)`, is 
quite extreme. The proportion of observations this extreme or more extreme than this are 
`r mean(results$statistic >= actual.value)`. The two-sided test has the same p-value: 
`r mean(abs(results$statistic) >= actual.value)`

In the following sections, I ask you to extend this test to a few other statistics and 
write up the answers to a few questions. 

### Portion of Satisfied Employees

Instead of looking at average satisfaction, let's look at employees who give a 
score of 5, 6, or 7. Perform a permutation test estimating whether or not difference
of this proportion (answering 5, 6, or 7) by assigned sex for males and females is likely 
the result of chance. 

Note that now we're talking about proportions, so rather than
taking the average of satisfaction, you'll need to be able to estimate the fraction 
of respondents whose answers fall within a certain range. Here's some example code that shows you how to create a column like this with `mutate`.

```{r}
# to get you started, here's the initial proportion
d %>% 
  mutate(satisfied = if_else(satisfaction %in% c(5,6,7), 1, 0)) %>% 
  group_by(assigned_sex) %>% 
  summarize(`Portion Satisfied` = mean(satisfied)) %>% 
  rename(Gender = assigned_sex) %>% # make the column header nice
  knitr::kable(digits = 2)

```

This code creates a new column called `satisfied`, then averages that 
by assigned sex, and presents the results in a nice looking table. We can see
that 37% of males are satisfied while only 19% of females are. 

There's one thing that this code _doesn't_ do: make that new column in the data permanently. In
order to get that new `satisfied` column to stay in the data frame, just assign
it back to itself with a line like this: 

```{r}
d <- d %>% 
  mutate(satisfied = if_else(satisfaction %in% c(5,6,7), 1, 0))
```

Sometimes you just want to create a new column temporarily, perhaps if it just
exists for a chart or table. Other times it's more convenient to just add
the column into the data as we do above.

When you finish the permutation steps for this section, once again 
plot the distribution of the replicates and interpret the results. 

```{r satisfied-prop, message=F}
# Using "cache=T" means that the simulation is only run once and then stored. 
# This is convenient for long-running calculations, but you should turn it off
# if you make changes to the code and need the block to be re-run.female.score <- mean(d$satisfaction[d$assigned_sex=="female"] >= 5)

get.proportion.satisfaction.diff <- function(x){
  male.score <- mean(x$satisfaction[x$assigned_sex=="male"] >= 5)
  female.score <- mean(x$satisfaction[x$assigned_sex=="female"] >= 5)
  return(male.score - female.score)
}

actual.value <- get.proportion.satisfaction.diff(d) 

n.sim <- 9999

results <- tibble(statistic = c(actual.value,
                                rep(NA,n.sim)))
new.d <- d %>% 
  select(assigned_sex,satisfaction)

for(i in 2:nrow(results)){
  new.d$assigned_sex <- sample(new.d$assigned_sex)
  results$statistic[i] <- get.proportion.satisfaction.diff(new.d)
}

ggplot(results,
       aes(x=statistic)) + 
  geom_density() + 
  geom_vline(xintercept=actual.value,color="red") + 
  theme_minimal() + 
  labs(x="Male Minus Female Satisfaction Proportion",
       y="")

```


Based on the satisfaction survey, the difference in proportion of people reporting a satisfaction 5 or above between males and females is `r round(actual.value, 2)`. This is our test statistic and is displayed in the above graph as the vertical red line. According to the permutation test, the proportion of observations this extreme or more extreme is `r mean(abs(results$statistic) >= actual.value)`. The difference in satisfaction proportions collected in the survey appears to be highly significant.  
     
### Non-Binary Satisfaction

There are 10 non-binary employees. Based on this new measure of 
satisfaction (answering 5, 6, or 7), do we see different levels
of satisfaction between our "neither" group and the female group? Please
make a similar chart and interpret it.

```{r non-binary-prop, message=F}
get.proportion.satisfaction.diff <- function(x){
  female.score <- mean(x$satisfaction[x$assigned_sex=="female"] >= 5)
  nonbinary.score <- mean(x$satisfaction[x$assigned_sex=="neither"] >= 5)
  return(female.score - nonbinary.score)
}

actual.value <- get.proportion.satisfaction.diff(d) 

n.sim <- 9999

results <- tibble(statistic = c(actual.value,
                                rep(NA,n.sim)))
new.d <- d %>% 
  select(assigned_sex,satisfaction)

for(i in 2:nrow(results)){
  new.d$assigned_sex <- sample(new.d$assigned_sex)
  results$statistic[i] <- get.proportion.satisfaction.diff(new.d)
}

ggplot(results,
       aes(x=statistic)) + 
  geom_density() + 
  geom_vline(xintercept=actual.value,color="red") + 
  theme_minimal() + 
  labs(x="Female Minus Non-Binary Satisfaction Proportion",
       y="")

```

According to the survey, the difference in proportions of people who answered 5 or above between females and non-binary is `r actual.value`. In the permutation test, the proportion of observations that were at least this extreme was `r mean(abs(results$statistic) >= actual.value)`. This suggests that the difference in satisfaction between females and non-binary is not statistically significant. 

### Satisfaction by Location

The headquarters of aQuantive were in Seattle, but about half the employees 
were in New York, the nexus of advertising in the US. The data show lower
satisfaction for New York employees: 
```{r loc-sat-tbl}
d %>% 
  group_by(location) %>% 
  summarize(`Mean Sat.`=mean(satisfaction)) %>% 
  knitr::kable()
```

In this section, perform a permutation test on satisfaction by location and report 
the results. 

```{r location-sat, message=F}
get.location.satisfaction.diff <- function(x){
  ny.score <- mean(x$satisfaction[x$location=="New York"] >= 5)
  sea.score <- mean(x$satisfaction[x$location=="Seattle"] >= 5)
  return(sea.score - ny.score)
}

actual.value <- get.location.satisfaction.diff(d) 

n.sim <- 9999

results <- tibble(statistic = c(actual.value,
                                rep(NA,n.sim)))
new.d <- d %>% 
  select(location,satisfaction)

for(i in 2:nrow(results)){
  new.d$location <- sample(new.d$location)
  results$statistic[i] <- get.location.satisfaction.diff(new.d)
}

ggplot(results,
       aes(x=statistic)) + 
  geom_density() + 
  geom_vline(xintercept=actual.value,color="red") + 
  theme_minimal() + 
  labs(x="New York Minus Seattle Satisfaction Proportion",
       y="")

mean(abs(results$statistic) >= actual.value)
```


The difference in proportions of people reporting satisfaction scores 5 of greater between Seattle and New York is `r actual.value`. In the permutation test, the proportion of observations at least as extreme as this is `r mean(abs(results$statistic) >= actual.value)`. Assuming an alpha level of 0.05, these results indicate that the difference in satisfaction proportions between the two cities is not significant.


### Median Satisfaction

The mean of the response is amenable to a t-test (if we were working with a 
a _sample_ and not a _census_). This is because the mean of a sample has a distribution
that can be mathematically proven to come from the $t$ distribution. There is no
analogous result for the median, our robust measure of the center
of a distribution. In this section, please calculate the difference in 
medians between the male and female respondents. As before, plot the results 
and interpret them. 

```{r median-sat, message=F}

d %>% 
  group_by(assigned_sex) %>% 
  rename(Gender = assigned_sex) %>%
  summarize(`Median`=median(satisfaction)) %>% 
  knitr::kable()

get.median.sex.diff <- function(x){
  male.score <- median(x$satisfaction[x$assigned_sex=="male"])
  female.score <- median(x$satisfaction[x$assigned_sex=="female"])
  return(male.score - female.score)
}

actual.value <- get.median.sex.diff(d) 

n.sim <- 9999

results <- tibble(statistic = c(actual.value,
                                rep(NA,n.sim)))
new.d <- d %>% 
  select(assigned_sex,satisfaction)

for(i in 2:nrow(results)){
  new.d$assigned_sex <- sample(new.d$assigned_sex)
  results$statistic[i] <- get.median.sex.diff(new.d)
}

ggplot(results,
       aes(x=statistic)) + 
  geom_density() + 
  geom_vline(xintercept=actual.value,color="red") + 
  theme_minimal() + 
  labs(x="Male Median Minus Female Median",
       y="")

#Does a permutation sample still need to be run if the test statistic is zero (matches the null hypothesis)? Is there an instance where the normal distribution of the permutation results is not centered around zero (when the null is that there is no difference)?
```


Both males and females had a median satisfaction of 4, resulting in a zero difference between the two groups. All observations in the permutation sample were equal to or more extreme then this result, indicating that there is not a significant difference in median satisfactions between the two groups. 

### An Approach for Tenure

You *do not* need to write any code in this section. 

Imagine HR was interested in the relationship between tenure and satisfaction. 
Typically, correlation is used to measure this type of association, 
with the most critical assumption being that the relationship is linear. In this 
section, describe how you could carry out a test of significance with the `cor.test`
function. This function uses a result from almost 100 years ago that the standard
deviation of the correlation coefficient is $\frac{r \sqrt(n-2)}{\sqrt(1-r^2)}$ that 
relies on a mathematically sophisticated approach that uses the method of moments. 

Alternatively, you could test the significance using a permutation test. In this section,
give some detail for the key steps you'd take to test the significance of the 
correlation coefficient. 

1. Null hypothesis: $H_0$: r = 0
1. Statistic: Correlation coefficient <!-- I did this one for you! -->  
1. Permutation step: I would permute the tenure column and observe the correlation coefficient for each permutation. <!-- What permutation step would you carry out to test that 
                          is in accordance with the null hypothesis? --> 
1. Final comparison: I would compare the test statistic to the permutation observations and determine the proportion of observations that were as extreme or more extreme that the test statistic (p-value).  <!-- What comparison do you make at the end? -->                         
